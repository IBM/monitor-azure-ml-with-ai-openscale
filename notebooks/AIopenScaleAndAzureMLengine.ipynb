{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Azure Machine Learning Studio engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to log the payload for a model deployed on Microsoft Azure serving engine using AI OpenScale python sdk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contents\n",
    "- [1. Setup](#setup)\n",
    "- [2. Binding machine learning engine](#binding)\n",
    "- [3. Subscriptions](#subscription)\n",
    "- [4. Scoring and payload logging](#scoring)\n",
    "- [5. Feedback logging](#feedback)\n",
    "- [6. Data Mart](#datamart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Sample model creation using [Azure Machine Learning Studio](https://studio.azureml.net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Download training data set from [here](https://github.com/pmservice/wml-sample-models/raw/master/spark/product-line-prediction/data/GoSales_Tx.csv)\n",
    "- [Create an experiment in Azure ML Studio](https://docs.microsoft.com/en-us/azure/machine-learning/studio/create-experiment) using the diagram below. (You can search for each module in the palette by name)\n",
    "- When you get to the `Train Model` module, select the `Product Line` column as the label.\n",
    "- Run the experiment to train the model.\n",
    "- [Create (deploy) web service](https://docs.microsoft.com/en-us/azure/machine-learning/studio/publish-a-machine-learning-web-service) (Choose the `new` NOT `classic`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/pmservice/ai-openscale-tutorials/raw/master/notebooks/images/azure_product_line_model.png\" align=\"left\" alt=\"experiment\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Classic web services are not supported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Installation and authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade ibm-ai-openscale --no-cache | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import and initiate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_ai_openscale import APIClient\n",
    "from ibm_ai_openscale.supporting_classes import PayloadRecord\n",
    "from ibm_ai_openscale.supporting_classes.enums import InputDataType, ProblemType\n",
    "from ibm_ai_openscale.engines import *\n",
    "from ibm_ai_openscale.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ACTION: Get AI OpenScale `instance_guid` and `apikey`\n",
    "\n",
    "[Install IBM Cloud (bluemix) console](https://console.bluemix.net/docs/cli/reference/ibmcloud/download_cli.html#install_use)\n",
    "\n",
    "Use the IBM Cloud CLI to get an api key:\n",
    "```bash\n",
    "ibmcloud login --sso\n",
    "ibmcloud iam api-key-create 'my_key'\n",
    "```\n",
    "\n",
    "Get your AI OpenScale instance GUID:\n",
    "> if your resource group is different than `default` switch to the resource group containing AI OpenScale instance\n",
    "\n",
    "```bash\n",
    "ibmcloud target -g <myResourceGroup>\n",
    "```\n",
    "\n",
    "Get details of the instance:\n",
    "```bash\n",
    "ibmcloud resource service-instance `AI-OpenScale-instance_name`\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's define some constants required to set up data mart:\n",
    "\n",
    "- AIOS_CREDENTIALS\n",
    "- POSTGRES_CREDENTIALS\n",
    "- SCHEMA_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIOS_CREDENTIALS = {\n",
    "  \"url\": \"https://api.aiopenscale.cloud.ibm.com\",\n",
    "  \"instance_guid\": \"****\",\n",
    "  \"apikey\": \"****\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSTGRES_CREDENTIALS = {\n",
    "    \"db_type\": \"postgresql\",\n",
    "    \"uri_cli_1\": \"xxx\",\n",
    "    \"maps\": [],\n",
    "    \"instance_administration_api\": {\n",
    "        \"instance_id\": \"xxx\",\n",
    "        \"root\": \"xxx\",\n",
    "        \"deployment_id\": \"xxx\"\n",
    "    },\n",
    "    \"name\": \"xxx\",\n",
    "    \"uri_cli\": \"xxx\",\n",
    "    \"uri_direct_1\": \"xxx\",\n",
    "    \"ca_certificate_base64\": \"xxx\",\n",
    "    \"deployment_id\": \"xxx\",\n",
    "    \"uri\": \"xxx\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHEMA_NAME = 'data_mart_for_azure'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create schema for data mart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_postgres_schema(postgres_credentials=POSTGRES_CREDENTIALS, schema_name=SCHEMA_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = APIClient(AIOS_CREDENTIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 DataMart setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.data_mart.setup(db_credentials=POSTGRES_CREDENTIALS, schema=SCHEMA_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mart_details = client.data_mart.get_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"binding\"></a>\n",
    "## 2. Bind machine learning engines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Bind  `Azure` machine learning engine\n",
    "\n",
    "Provide credentials using following fields:\n",
    "- `client_id`\n",
    "- `client_secret`\n",
    "- `subscription_id`\n",
    "- `tenant`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_ENGINE_CREDENTIALS = {\n",
    "    \"client_id\": \"***\",\n",
    "    \"client_secret\": \"***\",\n",
    "    \"subscription_id\": \"***\",\n",
    "    \"tenant\": \"***\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binding_uid = client.data_mart.bindings.add('My Azure ML Studio engine', AzureMachineLearningInstance(AZURE_ENGINE_CREDENTIALS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bindings_details = client.data_mart.bindings.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.data_mart.bindings.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"subsciption\"></a>\n",
    "## 3. Subscriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Add subscriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List available deployments.\n",
    "\n",
    "**Note:** Depending on the number of assets it may take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.data_mart.bindings.list_assets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Action:** Assign your source_uid to `source_uid` variable below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_uid = 'xxxxxx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription = client.data_mart.subscriptions.add(\n",
    "            AzureMachineLearningAsset(source_uid=source_uid,\n",
    "                                      binding_uid=binding_uid,\n",
    "                                      input_data_type=InputDataType.STRUCTURED,\n",
    "                                      problem_type=ProblemType.MULTICLASS_CLASSIFICATION,\n",
    "                                      label_column='PRODUCT_LINE',\n",
    "                                      prediction_column='Scored Labels'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get subscriptions list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscriptions = client.data_mart.subscriptions.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscriptions_uids = client.data_mart.subscriptions.get_uids()\n",
    "print(subscriptions_uids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List subscriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.data_mart.subscriptions.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"scoring\"></a>\n",
    "## 4. Scoring and payload logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Score the product line model and measure response time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "\n",
    "subscription_details = subscription.get_details()\n",
    "scoring_url = subscription_details['entity']['deployments'][0]['scoring_endpoint']['url']\n",
    "\n",
    "data = {\n",
    "    \"Inputs\": {\n",
    "        \"input1\":\n",
    "            [\n",
    "                {\n",
    "                    'GENDER': \"F\",\n",
    "                    'AGE': 27,\n",
    "                    'MARITAL_STATUS': \"Single\",\n",
    "                    'PROFESSION': \"Professional\",\n",
    "                    'PRODUCT_LINE': \"Personal Accessories\",\n",
    "                }\n",
    "            ],\n",
    "    },\n",
    "    \"GlobalParameters\": {\n",
    "    }\n",
    "}\n",
    "\n",
    "body = str.encode(json.dumps(data))\n",
    "\n",
    "token = subscription_details['entity']['deployments'][0]['scoring_endpoint']['credentials']['token']\n",
    "headers = subscription_details['entity']['deployments'][0]['scoring_endpoint']['request_headers']\n",
    "headers['Authorization'] = ('Bearer ' + token)\n",
    "\n",
    "start_time = time.time()\n",
    "response = requests.post(url=scoring_url, data=body, headers=headers)\n",
    "response_time = int(time.time() - start_time)*1000\n",
    "result = response.json()\n",
    "\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Store the request and response in payload logging table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform the model's input and output to the format compatible with AI OpenScale standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_data = {'fields': list(data['Inputs']['input1'][0]),\n",
    "           'values': [list(x.values()) for x in data['Inputs']['input1']]}\n",
    "\n",
    "response_data = {'fields': list(result['Results']['output1'][0]),\n",
    "            'values': [list(x.values()) for x in result['Results']['output1']]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store the payload using Python SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint:** You can embed payload logging code into your custom deployment so it is logged automatically each time you score the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_list = [PayloadRecord(request=request_data, response=response_data, response_time=response_time), \n",
    "                PayloadRecord(request=request_data, response=response_data, response_time=response_time)]\n",
    "\n",
    "for i in range(1, 10):\n",
    "    records_list.append(PayloadRecord(request=request_data, response=response_data, response_time=response_time))\n",
    "\n",
    "subscription.payload_logging.store(records=records_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store the payload using REST API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the token first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_endpoint = \"https://iam.bluemix.net/identity/token\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/x-www-form-urlencoded\",\n",
    "    \"Accept\": \"application/json\"\n",
    "}\n",
    "\n",
    "data = {\n",
    "    \"grant_type\":\"urn:ibm:params:oauth:grant-type:apikey\",\n",
    "    \"apikey\":AIOS_CREDENTIALS[\"apikey\"]\n",
    "}\n",
    "\n",
    "req = requests.post(token_endpoint, data=data, headers=headers)\n",
    "token = req.json()['access_token']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the payload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, uuid\n",
    "\n",
    "PAYLOAD_STORING_HREF_PATTERN = '{}/v1/data_marts/{}/scoring_payloads'\n",
    "endpoint = PAYLOAD_STORING_HREF_PATTERN.format(AIOS_CREDENTIALS['url'], AIOS_CREDENTIALS['data_mart_id'])\n",
    "\n",
    "payload = [{\n",
    "    'binding_id': binding_uid, \n",
    "    'deployment_id': subscription.get_details()['entity']['deployments'][0]['deployment_id'], \n",
    "    'subscription_id': subscription.uid, \n",
    "    'scoring_id': str(uuid.uuid4()), \n",
    "    'response': response_data,\n",
    "    'request': request_data\n",
    "}]\n",
    "\n",
    "\n",
    "headers = {\"Authorization\": \"Bearer \" + token}\n",
    "      \n",
    "req_response = requests.post(endpoint, json=payload, headers = headers)\n",
    "\n",
    "print(\"Request OK: \" + str(req_response.ok))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"feedback\"></a>\n",
    "## 5. Feedback logging & quality (accuracy) monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable quality monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to provide the monitoring `threshold` and `min_records` (minimal number of feedback records)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription.quality_monitoring.enable(threshold=0.7, min_records=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedback records logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feedback records are used to evaluate your model. The predicted values are compared to real values (feedback records)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the schema of feedback table using the below method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription.feedback_logging.print_table_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feedback records can be sent to the feedback table using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [\"GENDER\", \"AGE\", \"MARITAL_STATUS\", \"PROFESSION\", \"PRODUCT_LINE\"]\n",
    "\n",
    "records = [\n",
    "    [\"F\", \"27\", \"Single\", \"Professional\", \"Personal Accessories\"],\n",
    "    [\"M\", \"27\", \"Single\", \"Professional\", \"Personal Accessories\"]]\n",
    "\n",
    "for i in range(1,10):\n",
    "    records.append([\"F\", \"27\", \"Single\", \"Professional\", \"Personal Accessories\"])\n",
    "\n",
    "subscription.feedback_logging.store(feedback_data=records, fields=fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run quality monitoring on demand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, quality monitoring is run on hourly schedule. You can also trigger it on demand using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_details = subscription.quality_monitoring.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the monitoring runs in the background you can use the method below to check the status of the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = run_details['status']\n",
    "id = run_details['id']\n",
    "\n",
    "print(\"Run status: {}\".format(status))\n",
    "\n",
    "start_time = time.time()\n",
    "elapsed_time = 0\n",
    "\n",
    "while status != 'completed' and elapsed_time < 60:\n",
    "    time.sleep(10)\n",
    "    run_details = subscription.quality_monitoring.get_run_details(run_uid=id)\n",
    "    status = run_details['status']\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"Run status: {}\".format(status))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the quality metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription.quality_monitoring.show_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all calculated metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_uids = subscription.get_deployment_uids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription.quality_monitoring.get_metrics(deployment_uid=deployment_uids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"datamart\"></a>\n",
    "## 6. Get the logged data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Payload logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print schema of payload_logging table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription.payload_logging.print_table_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show (preview) the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription.payload_logging.describe_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Return the table content as pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = subscription.payload_logging.get_table_content(format='pandas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Feddback logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the schema of table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription.feedback_logging.print_table_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview table content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription.feedback_logging.show_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe table (calulcate basic statistics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription.feedback_logging.describe_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get table content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_pd = subscription.feedback_logging.get_table_content(format='pandas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Quality metrics table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription.quality_monitoring.print_table_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription.quality_monitoring.show_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Performance metrics table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription.performance_monitoring.print_table_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription.performance_monitoring.show_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Data Mart measurement facts table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.data_mart.get_deployment_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors\n",
    "Lukasz Cmielowski, PhD, is an Automation Architect and Data Scientist at IBM with a track record of developing enterprise-level applications that substantially increases clients' ability to turn data into actionable knowledge."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
